package ingestor

import (
	"context"
	"fmt"
	"log"
	"time"

	"to-de-olho-backend/internal/application"
	"to-de-olho-backend/internal/domain"

	"github.com/jackc/pgx/v5/pgxpool"
)

// IncrementalSyncManager gerencia sincroniza√ß√µes incrementais
type IncrementalSyncManager struct {
	deputadosService   *application.DeputadosService
	proposicoesService *application.ProposicoesService
	analyticsService   application.AnalyticsServiceInterface
	db                 *pgxpool.Pool
	cache              application.CachePort
}

// SyncMetrics m√©tricas da sincroniza√ß√£o
type SyncMetrics struct {
	StartTime          time.Time     `json:"start_time"`
	EndTime            time.Time     `json:"end_time"`
	Duration           time.Duration `json:"duration"`
	DeputadosUpdated   int           `json:"deputados_updated"`
	ProposicoesUpdated int           `json:"proposicoes_updated"`
	ErrorsCount        int           `json:"errors_count"`
	Errors             []string      `json:"errors,omitempty"`
	SyncType           string        `json:"sync_type"` // "daily", "quick"
}

// NewIncrementalSyncManager cria novo gerenciador de sync incremental
func NewIncrementalSyncManager(
	deputadosService *application.DeputadosService,
	proposicoesService *application.ProposicoesService,
	analyticsService application.AnalyticsServiceInterface,
	db *pgxpool.Pool,
	cache application.CachePort,
) *IncrementalSyncManager {
	return &IncrementalSyncManager{
		deputadosService:   deputadosService,
		proposicoesService: proposicoesService,
		analyticsService:   analyticsService,
		db:                 db,
		cache:              cache,
	}
}

// ExecuteDailySync executa sincroniza√ß√£o completa di√°ria
func (ism *IncrementalSyncManager) ExecuteDailySync(ctx context.Context) error {
	metrics := &SyncMetrics{
		StartTime: time.Now(),
		SyncType:  "daily",
		Errors:    []string{},
	}

	log.Println("üåÖ Iniciando sincroniza√ß√£o di√°ria completa")

	// 1. Sincronizar deputados (base fundamental)
	if err := ism.syncDeputados(ctx, metrics); err != nil {
		metrics.Errors = append(metrics.Errors, fmt.Sprintf("Deputados: %v", err))
		metrics.ErrorsCount++
		log.Printf("‚ùå Erro na sincroniza√ß√£o de deputados: %v", err)
	}

	// 2. Sincronizar proposi√ß√µes das √∫ltimas 24h
	if err := ism.syncRecentProposicoes(ctx, metrics); err != nil {
		metrics.Errors = append(metrics.Errors, fmt.Sprintf("Proposi√ß√µes: %v", err))
		metrics.ErrorsCount++
		log.Printf("‚ùå Erro na sincroniza√ß√£o de proposi√ß√µes: %v", err)
	}

	// 3. Limpar cache antigo
	if err := ism.cleanupOldCache(ctx); err != nil {
		log.Printf("‚ö†Ô∏è  Aviso: erro na limpeza de cache: %v", err)
	}

	// Finalizar m√©tricas
	metrics.EndTime = time.Now()
	metrics.Duration = metrics.EndTime.Sub(metrics.StartTime)

	// Atualizar rankings analytics ap√≥s sincroniza√ß√£o completa
	if ism.analyticsService != nil {
		log.Println("üìä Atualizando rankings e analytics...")
		if err := ism.analyticsService.AtualizarRankings(ctx); err != nil {
			metrics.Errors = append(metrics.Errors, fmt.Sprintf("Analytics: %v", err))
			metrics.ErrorsCount++
			log.Printf("‚ö†Ô∏è  Erro ao atualizar analytics: %v", err)
		} else {
			log.Println("‚úÖ Rankings atualizados com sucesso")
		}
	}

	// Persistir m√©tricas
	if err := ism.saveSyncMetrics(ctx, metrics); err != nil {
		log.Printf("‚ö†Ô∏è  Erro ao salvar m√©tricas: %v", err)
	}

	log.Printf("üìä Sync di√°rio: %d deputados, %d proposi√ß√µes, %d erros em %v",
		metrics.DeputadosUpdated, metrics.ProposicoesUpdated,
		metrics.ErrorsCount, metrics.Duration)

	if metrics.ErrorsCount > 0 {
		return fmt.Errorf("sincroniza√ß√£o com %d erros", metrics.ErrorsCount)
	}

	return nil
}

// ExecuteQuickSync executa sincroniza√ß√£o r√°pida (apenas dados cr√≠ticos)
func (ism *IncrementalSyncManager) ExecuteQuickSync(ctx context.Context) error {
	metrics := &SyncMetrics{
		StartTime: time.Now(),
		SyncType:  "quick",
		Errors:    []string{},
	}

	log.Println("‚ö° Iniciando sincroniza√ß√£o r√°pida")

	// Apenas proposi√ß√µes das √∫ltimas 4h (mais vol√°teis)
	if err := ism.syncRecentProposicoes(ctx, metrics); err != nil {
		metrics.Errors = append(metrics.Errors, fmt.Sprintf("Proposi√ß√µes: %v", err))
		metrics.ErrorsCount++
	}

	metrics.EndTime = time.Now()
	metrics.Duration = metrics.EndTime.Sub(metrics.StartTime)

	log.Printf("‚ö° Sync r√°pido: %d proposi√ß√µes, %d erros em %v",
		metrics.ProposicoesUpdated, metrics.ErrorsCount, metrics.Duration)

	return nil
}

// syncDeputados sincroniza lista completa de deputados
func (ism *IncrementalSyncManager) syncDeputados(ctx context.Context, metrics *SyncMetrics) error {
	log.Println("üë• Sincronizando deputados...")

	// Buscar deputados atuais
	deputados, source, err := ism.deputadosService.ListarDeputados(ctx, "", "", "")
	if err != nil {
		return fmt.Errorf("erro ao buscar deputados: %w", err)
	}

	// S√≥ contar como atualiza√ß√£o se veio da API
	if source == "api" {
		metrics.DeputadosUpdated = len(deputados)
		log.Printf("‚úÖ %d deputados sincronizados da API", len(deputados))
	} else {
		log.Printf("üìÑ Deputados obtidos do %s", source)
	}

	return nil
}

// syncRecentProposicoes sincroniza proposi√ß√µes recentes
func (ism *IncrementalSyncManager) syncRecentProposicoes(ctx context.Context, metrics *SyncMetrics) error {
	log.Println("üìú Sincronizando proposi√ß√µes recentes...")

	// Filtro para proposi√ß√µes das √∫ltimas 24h
	filtros := &domain.ProposicaoFilter{
		DataApresentacaoInicio: func() *time.Time {
			t := time.Now().AddDate(0, 0, -1) // √öltimas 24h
			return &t
		}(),
		Ordem:      "DESC",
		OrdenarPor: "dataApresentacao",
		Limite:     50, // Limite conservador para sync incremental
	}

	proposicoes, _, source, err := ism.proposicoesService.ListarProposicoes(ctx, filtros)
	if err != nil {
		return fmt.Errorf("erro ao buscar proposi√ß√µes: %w", err)
	}

	if source == "api" {
		metrics.ProposicoesUpdated = len(proposicoes)
		log.Printf("‚úÖ %d proposi√ß√µes sincronizadas da API", len(proposicoes))
	} else {
		log.Printf("üìÑ Proposi√ß√µes obtidas do %s", source)
	}

	return nil
}

// cleanupOldCache remove entradas de cache antigas
func (ism *IncrementalSyncManager) cleanupOldCache(ctx context.Context) error {
	log.Println("üßπ Limpando cache antigo...")

	// Por enquanto √© placeholder - Redis tem TTL autom√°tico
	// Futuramente podemos implementar limpeza manual de chaves espec√≠ficas

	return nil
}

// saveSyncMetrics persiste m√©tricas da sincroniza√ß√£o
func (ism *IncrementalSyncManager) saveSyncMetrics(ctx context.Context, metrics *SyncMetrics) error {
	query := `
		INSERT INTO sync_metrics (
			sync_type, start_time, end_time, duration_ms,
			deputados_updated, proposicoes_updated, errors_count, errors
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
	`

	durationMS := int(metrics.Duration.Milliseconds())
	var errorsJSON *string
	if len(metrics.Errors) > 0 {
		errorsStr := fmt.Sprintf("%v", metrics.Errors)
		errorsJSON = &errorsStr
	}

	_, err := ism.db.Exec(ctx, query,
		metrics.SyncType,
		metrics.StartTime,
		metrics.EndTime,
		durationMS,
		metrics.DeputadosUpdated,
		metrics.ProposicoesUpdated,
		metrics.ErrorsCount,
		errorsJSON,
	)

	if err != nil {
		return fmt.Errorf("erro ao salvar m√©tricas: %w", err)
	}

	return nil
}

// GetSyncStats retorna estat√≠sticas de sincroniza√ß√£o
func (ism *IncrementalSyncManager) GetSyncStats(ctx context.Context, days int) ([]SyncMetrics, error) {
	query := `
		SELECT sync_type, start_time, end_time, duration_ms,
		       deputados_updated, proposicoes_updated, errors_count, errors
		FROM sync_metrics 
		WHERE start_time >= NOW() - INTERVAL '%d days'
		ORDER BY start_time DESC
		LIMIT 50
	`

	rows, err := ism.db.Query(ctx, fmt.Sprintf(query, days))
	if err != nil {
		return nil, fmt.Errorf("erro ao buscar estat√≠sticas: %w", err)
	}
	defer rows.Close()

	var stats []SyncMetrics
	for rows.Next() {
		var metric SyncMetrics
		var durationMS int
		var errorsJSON *string

		err := rows.Scan(
			&metric.SyncType,
			&metric.StartTime,
			&metric.EndTime,
			&durationMS,
			&metric.DeputadosUpdated,
			&metric.ProposicoesUpdated,
			&metric.ErrorsCount,
			&errorsJSON,
		)
		if err != nil {
			continue
		}

		metric.Duration = time.Duration(durationMS) * time.Millisecond
		if errorsJSON != nil {
			metric.Errors = []string{*errorsJSON}
		}

		stats = append(stats, metric)
	}

	return stats, nil
}
